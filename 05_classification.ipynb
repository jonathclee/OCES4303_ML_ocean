{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9e8ad7-e2a7-41bc-9ec6-734f29fe4207",
   "metadata": {},
   "source": [
    "*updated 05 Aug 2025, Julian Mak (whatever with copyright, do what you want with this)\n",
    "\n",
    "### As part of material for OCES 4303 \"AI and Machine Learning in Marine Science\" delivered at HKUST\n",
    "\n",
    "For the latest version of the material, go to the public facing [GitHub](https://github.com/julianmak/OCES4303_ML_ocean) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021411e-ee13-4aad-a43f-20de846a775b",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Classification tasks\n",
    "\n",
    "So far we have dealt with ***regression***, which we assume the target is continuously varying. ***Classification*** would be the discrete version of that, i.e. predict the discrete labels given the data. Examples of this might be:\n",
    "\n",
    "* Given attributes from the `penguins` data, predict the species\n",
    "* Classify whether an image is that of a cat or a dog\n",
    "* Predicting whether an Argo temperature/sainity profile is from a particular geographical location if I label it accordingly (e.g. from the Atlantic)\n",
    "\n",
    "We are going to come back to these again when we get to decision trees / random forests, and neural networks (which can also do regression). For now we are introduce some other algorithms for the classification tasks, with some detours that will also be useful later on when we deal with trees and neural networks.\n",
    "\n",
    "> ## Key Objective(s)\n",
    "> 1. Understand the difference between regression and classification (they are not that different...)\n",
    "> 2. Appreciate that classification is closerly related to finding separation between labelled data (and separation again depends on what you mean by distance).\n",
    "> 3. Introduce other loss functions, some of which are closely related to ***activation functions*** that we will encounter when dealing with neural networks.\n",
    "> 4. Do some basic classification tasks.\n",
    "\n",
    "For most of the below I am going to use some artificial data for the code demonstration, before performing similar calculations with the penguins data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622477f-25e0-4a6f-bc8f-2cdc8ac25946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722be69-0afd-424f-bdb0-2ec65512fee4",
   "metadata": {},
   "source": [
    "---\n",
    "## a) Linear/Quadratic Discriminant Analysis (L/QDA)\n",
    "\n",
    "The idea of classification is to find a separator between two sets of data, then you can say if my data lies to one side it is class $A$ etc. The main idea of ***LDA*** and ***QDA*** is that you find a linear and quadratic separator between the data. Without going into the subtleties, the two methods here have closed form solutions and no hyperparameters to tune, and are generally quite robust. For some more details, you could start with [here](https://scikit-learn.org/stable/modules/lda_qda.html).\n",
    "\n",
    "I am going to leverage the moon data for this. The creation mechanism already has spits out the labels (I just happened to suppress it last time); you could have make label yourself through the procedures in the last lecture in principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97335299-a8de-49a3-ba0a-8cb73b8a0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create moon data, cluster and then label them\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# use different colours for reasons later\n",
    "colors = \"rb\"  # red blue\n",
    "\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=0)     # labels are numeric: 0 and 1\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X[Y==i, 0], X[Y==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\");\n",
    "ax.set_xlim([-1.5, 2.5]); ax.set_ylim([-0.8, 1.2])\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6f1b5-ab50-4186-8c77-b32d0ddd0a89",
   "metadata": {},
   "source": [
    "Going to first demonstrate LDA. We do train/test split, but we don't really need to standarise for this dataset. The predictions return labels, and the check on the score is simply how many labels did it get correct (`np.sum(Y_pred == Y_test)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd9cdb-c99b-43c8-af24-dc1b0949ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# withhold 20% of data that model training does not see, and use that to test skill\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ea8ce-ba9b-4eac-9af1-e9f76cc42622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c3c25-114a-4e3f-bfd3-f400cd4cae9b",
   "metadata": {},
   "source": [
    "We have broad diagnostics of skill but it may be of interest to actually see what is the boundary the model decided to find. Here we can leverage `sklearn.inspection.DecisionBoundaryDisplay` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599bab4-739f-464e-9cf3-dc8d209c0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# do a prediction but on full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X[Y_pred==i, 0], X[Y_pred==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict_proba\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=\"RdBu\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict_proba\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5],  # because the labels are 0 or 1, and (0 + 1)/2 = 0.5\n",
    ")\n",
    "ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\");\n",
    "ax.set_xlim([-1.5, 2.5]); ax.set_ylim([-0.8, 1.2])\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b244252-c570-4d39-ab25-ed95fdeb71b7",
   "metadata": {},
   "source": [
    "So everything above the line is predicted as red and below is blue, and there are some parts of the moon that gets predicted wrong. This is not entirely surprising because for this case there is no linear line in 2d that cuts the data cleanly in half.\n",
    "\n",
    "Before we move on to QDA, note that you can use LDA as a way to do dimension reduction. For this problem the data is embedded in 2d, so the reduction goes to 1d. Within the lower dimension the idea is to find the best separator, which in this case is some horizontal line. Given the data mixing, there is no clean separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b42252-3a58-46ba-a2a3-00759f3025b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction of dimenion by 1 in this case\n",
    "X_transform = model.transform(X_train)\n",
    "\n",
    "# plot out the transforms + projected data with labels\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X_transform[Y_train == i], f\"{colors[i]}x\", alpha=0.7)\n",
    "ax.set_xlabel(r\"$\\hat{x}$\")\n",
    "ax.set_title(r\"LDA projection of moon data\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedff8e0-e507-4550-af49-e3ac07652602",
   "metadata": {},
   "source": [
    "A similar thing can be done with QDA, although there is no dimension reduction procedure here with the `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e928799-7f55-4e01-a0f4-ea34729ca0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# fit models\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "print(\" \")\n",
    "\n",
    "# do a prediction but on full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X[Y_pred==i, 0], X[Y_pred==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict_proba\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=\"RdBu\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict_proba\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5],  # because the labels are 0 or 1, and (0 + 1)/2 = 0.5\n",
    ")\n",
    "ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\");\n",
    "ax.set_xlim([-1.5, 2.5]); ax.set_ylim([-0.8, 1.2])\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7209d9-d47c-40a3-831f-f727415b726f",
   "metadata": {},
   "source": [
    "Here the boundary is a quadratic curve that gives a marginally better performance than LDA. This is perhaps not surprising because the separator has more complexity and is slightly more flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf1ad0-c22b-4b47-8dce-22594b3087fc",
   "metadata": {},
   "source": [
    "> <span style=\"color:red\">Q.</span> I didn't standardise the data, and I am fairly sure it doesn't actually do anything for this case. Convince yourself there is some merit in that assertion.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Here you probably don't need to check for robustness and cross-validation as such, because the data and the methods are simple enough, but give that a go to see how the prediction scores change.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Try something similar for the swiss roll or S curve data embedded in 3d. The way I would do it is \"unroll\" the data somehow (use a dimension reduction technique to 2d), then artificially draw a line in the plane and call one half something and another half something else. You could also try and have multiple labels (which we will see later with the penguins data).\n",
    ">\n",
    "> Note that the `DecisionBoundaryDisplay` routine will complain if the predictor requires more than two inputs (because plotting a surface of separation is hard). You could of course include dimension reduction techniques in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f1819-0e51-4e8c-8399-c2cfb6854b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e47de41-8bd9-4ef2-b18a-c7a2badc2e25",
   "metadata": {},
   "source": [
    "---\n",
    "## b) Support Vector Machine (SVM)\n",
    "\n",
    "If we take the moon data example above then you can argue there is no way I can separate the data unless I have enough complexity, which may then give me over-fitting. But that's only if I am stuck 2d; see below for an artificial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f60112-65c1-4731-a6e0-ac3433df4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different colours for reasons later\n",
    "colors = \"rb\"  # red blue\n",
    "\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=0)     # labels are numeric: 0 and 1\n",
    "\n",
    "# artificially lift the data into 3d\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "# lift the data into 3d and shift the z-coordinate but some constant\n",
    "X_3d = np.zeros((X.shape[0], X.shape[1]+1))  # make a bigger array\n",
    "X_3d[:, :-1] = X                             # dump in the old data\n",
    "X_3d[:, 2] = np.where(Y==0, 0.0, 1.0)        # add a z-coord related to label\n",
    "\n",
    "elev_range = [90, 45, 10]\n",
    "for j in range(3):\n",
    "    ax = plt.subplot2grid((1, 3), (0, j), projection=\"3d\")\n",
    "    for i in range(2):\n",
    "        ax.plot(X_3d[Y==i, 0], X_3d[Y==i, 1], X_3d[Y==i, 2], f\"{colors[i]}x\", alpha=0.7)\n",
    "    ax.view_init(azim=-75, elev=elev_range[j])\n",
    "    ax.set_box_aspect((1, 1, 1))\n",
    "    ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\"); ax.set_zlabel(r\"$z$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce91a7d-4d54-409d-b599-19e8439f407f",
   "metadata": {},
   "source": [
    "If we do that then the separator is \"obvious\" to find. You can of course argue that I can arbitrarily promote the data to higher dimensions (effectively as a co-ordinate transformation of course), then I can always find a good separator (i.e. high-dimensional hyperplane) for it.\n",
    "\n",
    "The idea of ***Support Vector Machine*** (SVM) is essentially to fix a maximal separator between the labelled data, allowing for promotion to higher dimension space, but penalising that latter procedure. The result is again an optimisation problem.\n",
    "\n",
    "> NOTE: The details are a bit complicated in that you actually solve a ***dual problem*** using the ***kernel trick***. Not going to go into that.\n",
    "\n",
    "In `sklearn` SVM is in the module `svm`, and we can try and do the above but with default SVM. We are going to use `SVC` which is the basic one for classification. The default there uses the regularisation parameter `C=1` and `kernel=rbf` (Radial Basis Function). Have a look at [here](https://scikit-learn.org/stable/modules/svm.html) to see what those mean.\n",
    "\n",
    "> NOTE: You can also use SVM for doing regression (`SVR`); see extended exercise later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57ca0b-5e18-4611-b76c-760b82c12182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=0)     # labels are numeric: 0 and 1\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)\n",
    "\n",
    "# fit models\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "\n",
    "# do a prediction but on full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X[Y_pred==i, 0], X[Y_pred==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",  # SVM has no probability associated with predictions\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=\"RdBu\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5],  # because the labels are 0 or 1, and (0 + 1)/2 = 0.5\n",
    ")\n",
    "ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\");\n",
    "ax.set_xlim([-1.5, 2.5]); ax.set_ylim([-0.8, 1.2])\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904ca30-2de5-4cbd-94d8-18dc51a1d98f",
   "metadata": {},
   "source": [
    "More or less what we expected! In this case we can get a perfect score because the data is in fact well-separated (but that's because the data noise level is fairly low).\n",
    "\n",
    "In the below case I am going to do a whole load of different variants. I will be using this multiple times, so I am going to wrap it up in a subroutine that varies by the input and output data.\n",
    "\n",
    "> NOTE: Unlike the one above where I use different data for training and testing, the ones below use all the data for fitting, because it is only there to demonstrate differences in behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbeb8c-26ad-4336-8026-3cd2da9a792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SVM_variants(X, Y, models, title, C=1.0):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for j in range(len(models)):\n",
    "    \n",
    "        model = models[j]\n",
    "        \n",
    "        # fit models\n",
    "        model.fit(X, Y)\n",
    "    \n",
    "        # basic skill diagnostics\n",
    "        Y_pred = model.predict(X)\n",
    "        N = len(Y)\n",
    "        skill_all = np.sum(Y_pred == Y)\n",
    "    \n",
    "        # do a prediction but on full data\n",
    "        ax = plt.subplot(2, 2, j+1)\n",
    "        for i in range(2):\n",
    "            ax.plot(X[Y_pred==i, 0], X[Y_pred==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "        DecisionBoundaryDisplay.from_estimator(model, X,\n",
    "            response_method=\"predict\",  # SVM has no probability associated with predictions\n",
    "            plot_method=\"pcolormesh\",\n",
    "            ax=ax,\n",
    "            cmap=\"RdBu\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        DecisionBoundaryDisplay.from_estimator(model, X,\n",
    "            response_method=\"predict\",\n",
    "            plot_method=\"contour\",\n",
    "            ax=ax,\n",
    "            alpha=1.0,\n",
    "            levels=[0.5],  # because the labels are 0 or 1, and (0 + 1)/2 = 0.5\n",
    "        )\n",
    "        if j % 2 == 0:\n",
    "            ax.set_ylabel(r\"$y$\")\n",
    "        if j > 1:\n",
    "            ax.set_xlabel(r\"$x$\")\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "        if (j == 1 or j == 3):\n",
    "            ax.set_yticklabels([])\n",
    "        ax.set_title(f\"{titles[j]}, full skill = {skill_all/N*100:.2f}%\")\n",
    "        ax.grid()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e698b-3383-4f60-b916-728b9d6f8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh data\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=random_state)\n",
    "\n",
    "# cycle through an array of models\n",
    "C = 1.0  # regularisation parameter (1.0 is the default, smaller is larger regularisation)\n",
    "models = (\n",
    "    svm.SVC(kernel='linear', C=C, random_state=random_state),\n",
    "    svm.SVC(kernel='rbf', gamma=0.7, C=C, random_state=random_state),\n",
    "    svm.SVC(kernel='poly', degree=3, C=C, random_state=random_state),\n",
    "    svm.LinearSVC(C=C, random_state=random_state),\n",
    ")\n",
    "titles = (\"linear kernel\", r\"RBF with $\\gamma$\", \"degree 3 kernel\", \"linear SVC\")\n",
    "\n",
    "fig = plot_SVM_variants(X, Y, models, titles, C=C);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabd511-c25f-4079-920a-01fa2990432a",
   "metadata": {},
   "source": [
    "> <span style=\"color:red\">Q.</span> Try the whole thing again but this time increase the noise in the data generation part (then we won't have a good separation).\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Try something similar for the swiss roll or S curve data embedded in 3d, with massaging of the data as before.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Explore different model parameters to see what that does, and cross-validate things where relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768bfdf-ab7b-4ba3-b864-4807670c023d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429517e1-fd5e-4d9c-bcdc-a5a8705b5d4e",
   "metadata": {},
   "source": [
    "### Things to be aware of: data scaling\n",
    "\n",
    "SVM is not scale-invariant and can be sensitive to scaling in the data. In the below case I artificially stretch the data in one co-ordinate by quite a large factor, and you can see the data starts behaving a bit strangely (particularly the `rbf` that previously had a 100% accuracy). \n",
    "\n",
    "Standardisation is recommended in general (try it for the penguins data later particularly if the `body_mass_g` feature is included, because that has completely different magnitudes compared to the others (and the fact that it doesn't even have comparable units...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d412568-b1f8-40c1-9293-242f0bb34cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificially scaled data\n",
    "random_state = 0\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=random_state)\n",
    "\n",
    "factor = 100\n",
    "X[:, 0] *= factor  # stretch it in one direction by a factor\n",
    "\n",
    "fig = plot_SVM_variants(X, Y, models, titles, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb474f22-4b09-4ba1-b3ae-111ea7a3a309",
   "metadata": {},
   "source": [
    "### Things to be aware of: unbalanced datasets\n",
    "\n",
    "SVM has issues if the dataset is unbalanced, by which I mean there is noticeably more data in one class than the other. In the below code I am going to artificially remove some data from one class and then do SVM on those again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a22c1e-fc1d-46bd-bb4e-a074c1de041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifically unbalanced data\n",
    "random_state = 0\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=random_state)\n",
    "\n",
    "# define amount of data to keep, find index, choose an integer selection, and overwrite array\n",
    "factor = 0.05\n",
    "inds_full = np.where(Y==1)[0]\n",
    "np.random.seed(random_state)  # force it to be deterministic\n",
    "inds = np.random.choice(inds_full, int(factor * len(inds_full)), replace=False)\n",
    "X = np.concatenate((X[Y==0, :], X[inds, :]), axis=0)\n",
    "Y = np.concatenate((Y[Y==0], Y[inds]))\n",
    "\n",
    "fig = plot_SVM_variants(X, Y, models, titles, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38966c-0dbe-4d68-9b61-6f4ec75e6f7e",
   "metadata": {},
   "source": [
    "Several possible ways to deal wuth this are (can be used in combination, and not all of them will fix everything):\n",
    "\n",
    "* remove some data from the larger class (but this is removing data which can be a problem with smaller datasets)\n",
    "* ***bootstrap*** to bulk out the class that is low on samples (but requires interpolation and/or knowing something about the pdf of the data)\n",
    "* pass `class_weight=\"balanced\"` when initialising the model\n",
    "* increase the regularisation `C` when initialising the model (in this case you want to DECREASE the value of `C` though)\n",
    "\n",
    "Below considers the latter two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147ce86-a4b6-4920-842e-95d9ebd9bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying model parameters for unbalanced dataset\n",
    "random_state = 0\n",
    "C = 0.75  # regularisation parameter (1.0 is the default, smaller is larger regularisation)\n",
    "models = (\n",
    "    svm.SVC(kernel='linear', C=C, random_state=random_state, class_weight=\"balanced\"),\n",
    "    svm.SVC(kernel='rbf', gamma=0.7, C=C, random_state=random_state, class_weight=\"balanced\"),\n",
    "    svm.SVC(kernel='poly', degree=3, C=C, random_state=random_state, class_weight=\"balanced\"),\n",
    "    svm.LinearSVC(C=C, random_state=random_state, class_weight=\"balanced\"),\n",
    ")\n",
    "\n",
    "fig = plot_SVM_variants(X, Y, models, titles, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66989f45-2b4b-4fb1-b815-b500277b9896",
   "metadata": {},
   "source": [
    "The rebalancing seems to improve the SVM using `rbf`, but has marginal response in the other ones.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Try the whole thing again but this time increase the noise in the data generation part (then we won't have a good separation).\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Try something similar for the swiss roll or S curve data embedded in 3d, with massaging of the data as before.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Explore different model parameters to see what that does, and cross-validate things where relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8183803-4879-4a9c-ac0a-c6bc2c692576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be5750cc-0df4-429f-af33-3616851c32c9",
   "metadata": {},
   "source": [
    "---\n",
    "## c) Stochastic Gradient Descent (SGD) with different choices of loss and penalisations\n",
    "\n",
    "So here I want to take a slight detour because some of the details will be relevant to neural networks later. We talked about ***gradient descent*** before as a means to solve the optimisation problem earlier: recally that for the landscape defined by the loss function $J$, around $J(\\theta_n)$, you want to probe for the gradient information, and update to get $\\theta_{n+1}$ depending on the direction where $J$ descends fastest. Formally to get the full gradient you would need to compute $J$ in some $n$-dimensional ball around $\\theta$ to find the optimal direction. \n",
    "\n",
    "The idea then is that you could consider some random directions instead of every direction, and use that to approximate for the gradient instead. You potentially take a less direct route to the minimum along the $J$ landscape, but it is cheaper, and you could in principle use the information in the previous iterations to help you along the way. If the number of directions is 1, it's called ***stochastic gradient descent***; if it's more than 1 it's called ***mini-batch*** gradient descent (but also sometimes just labelled as \"stochastic\"). \n",
    "\n",
    "This kind of method is useful particularly for things like neural networks where there are a lot of entries in $\\theta$ to adjust, so the dimensionality can be so large that full gradient descent is not computationally feasible. These type of methods also have some suggestion that it can sample the space better to not get stuck in a local minimum.\n",
    "\n",
    "So SGD itself is a method and not a classifier as such: when you choose the loss function (and appropriate penalisation) you define the type of classifier. For classifiers the kind of loss we want should be one-sided: you should incur a massive cost if you get the classification wrong. Below are some of the these: going to plot these out first before describing them.\n",
    "\n",
    "> NOTE: You can look through the code to see the mathematical form of these if you want; not going to type those out here... (I basically took the below graph from  [here](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html), although I renamed the variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b5f96-9984-4572-aa00-a7b501123da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole bunch of loss functions\n",
    "\n",
    "def modified_huber_loss(Y_true, Y_pred):\n",
    "    z = Y_pred * Y_true\n",
    "    loss = -4 * z\n",
    "    loss[z >= -1] = (1 - z[z >= -1]) ** 2\n",
    "    loss[z >= 1.0] = 0\n",
    "    return loss\n",
    "\n",
    "X = np.linspace(-4, 4, 101)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot([-4, 0, 0, 4], [1, 1, 0, 0], label=\"zero-one\")\n",
    "ax.plot(X, np.where(X < 1, 1 - X, 0), label=\"hinge\")\n",
    "ax.plot(X, -np.minimum(X, 0), label=\"perceptron\")\n",
    "ax.plot(X, np.log2(1 + np.exp(-X)), label=\"log\")\n",
    "ax.plot(X, np.where(X < 1, 1 - X, 0) ** 2, label=\"squared hinge\")\n",
    "ax.plot(X, modified_huber_loss(X, 1), \"--\", label=\"modified Huber\")\n",
    "ax.set_ylim((0, 8))\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$f(x)$\")\n",
    "ax.set_ylabel(r\"$\\mathcal{L}(f(x))$\")\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dbbca-ddc7-459d-8b4d-99e0e094a851",
   "metadata": {},
   "source": [
    "We are making the decision here that anything positive is correct, and negative is bad (you can flip these accordingly of course). Respectively, we have:\n",
    "\n",
    "* zero-one: No cost if correct, other incur a cost of one. This is not really implemented, and is not considered further.\n",
    "* hinge: It's called \"hinge\" because it looks like a door hinge (the bit that connects the door to the wall). You start incurring a cost from 1, and this scales up linearly as you get more and more wrong.\n",
    "* perceptron: It's called \"perceptron\" because it is used in ***perceptrons***, which we will encounter later when we deal with neural networks. This is like hinge but it starts activating at 0 instead of 1.\n",
    "* log: Because it follows a (shifted) logarithm. Starts activating sooner but scales up faster than hinge and perceptron (because log blows up to infinity faster than linear functions).\n",
    "* squared hinge: Because you take the hinge loss function and square it.\n",
    "* modified Huber: Bit like the squared hinge but is more smooth, has some numerical advantages.\n",
    "\n",
    "> NOTE: The main reason I wanted to digress into this here is that the loss functions defined here where flipped about the $y$-axis because possible candidates of ***activation functions***, which is important for neural networks later. For example, flipping the perceptron loss above would lead to ***ReLU***, which is usually the default activation for neural networks.\n",
    "\n",
    "A thing to note here is that the loss functions above are not convex and by itself may not have a minimum. A regularisation is usually needed; common choices are just the $L^1$, $L^2$ and elastic nets (a combination of both).\n",
    "\n",
    "For a SGD classifer we would import this from `sklearn.linear_model.SGDClassifier`, and passing the keyword `loss=` in. The default regulariser is $L^2$ (`penalty=\"l2\"`). Below are some specific cases:\n",
    "\n",
    "* `loss=\"hinge\"` and `penalty=\"l2\"` (the default if you just do `SDGClassifier()`: This reduces to linear SVM above.\n",
    "* `loss=\"modified_huber\"` is a bit like the above, but with punishes outliers more. Comes with probability measures of the decision (cf. allows for `response_method=\"predict_proba\"` in `DecisionBoundaryDisplay.from_estimator`)\n",
    "* `loss=\"log_loss\"` gives ***Logistic Regression***, which is really a classifier, although it has regression in the name. Sometimes called ***logit*** or ***Maximum Entropy*** classifier; not going to go into why that is.\n",
    "\n",
    "Below I am just going to one for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95351115-b8e6-4e5e-ad7b-c8031a22a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "n_samples = 600\n",
    "X, Y = make_moons(n_samples, noise=0.05, random_state=0)     # labels are numeric: 0 and 1\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)\n",
    "\n",
    "# fit models\n",
    "model = SGDClassifier(loss=\"log_loss\")  # just logistic regression, with L2 penalisation\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "print(\" \")\n",
    "\n",
    "# do a prediction but on full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for i in range(2):\n",
    "    ax.plot(X[Y_pred==i, 0], X[Y_pred==i, 1], f\"{colors[i]}x\", alpha=0.7)\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=\"RdBu\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5],  # because the labels are 0 or 1, and (0 + 1)/2 = 0.5\n",
    ")\n",
    "ax.set_xlabel(r\"$x$\"); ax.set_ylabel(r\"$y$\");\n",
    "ax.set_xlim([-1.5, 2.5]); ax.set_ylim([-0.8, 1.2])\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401d0a7-8c68-43a5-b003-0c5b39c3141f",
   "metadata": {},
   "source": [
    "> <span style=\"color:red\">Q.</span> You could also do logistic regression via `sklearn.linear_model.LogisticRegression`, and that has somewhat more options (mostly solvers) available. Convince yourself those two more or less do the same things.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Try some other combinations (e.g. linear SVM with $L^1$ penalisation, which promotes sparsity). You have to be a bit careful that convergence of the solver may become an issue.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> One thing of interest to later is the ***learning rate*** that you can specify in the classifier; this is effectively the size of steps the solver takes to iterate towards a minimum. Try the options beyond the default.\n",
    ">\n",
    "> This will be a possible model hyper-parameter that one might need to consider for cross-validation and helping for model convergence particularly when we deal with neural networks later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50afe9-5a0b-463f-9c6b-f7a55d4dad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "634d5191-c153-4137-ba01-9cb908aee0c6",
   "metadata": {},
   "source": [
    "---\n",
    "## Demonstration: penguins data\n",
    "\n",
    "The example here considers doing classification on penguins data (which has three labels). We are going to do the case where there are two features (so I can show decision boundaries), and cases where I throw in all four features.\n",
    "\n",
    "Recall that in `penguins` the `species` feature is text. We can convert that to numerical values via `sklearn.preprocessing.LabelEncoder`; going to load `StandardScaler` at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307caf81-8f7c-4cb6-992f-40a67645a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the penguin data\n",
    "option = \"remote\"\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"penguins.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/penguins.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# choose two particularly different features\n",
    "feature_names = [\"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = df[feature_names].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# turn target from text to numerical values\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(df[\"species\"])\n",
    "\n",
    "print(f\"{encoder.classes_} mapped to {encoder.transform(encoder.classes_)}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b9d98-6721-4ec9-b853-6b657e5b4792",
   "metadata": {},
   "source": [
    "I am going to do this wrong first by using `SVM` but not scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881430d-b74e-4c91-8df0-c7ba5bd45ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# withhold 20% of data that model training does not see, and use that to test skill\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)\n",
    "\n",
    "# fit a model\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "\n",
    "# plot out the predictions (circles should lie on top of crosses if completely correct)\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = plt.axes()\n",
    "ax.plot(Y_pred, 'bx', label=\"predictions\")\n",
    "ax.plot(Y_test, 'ro', fillstyle=\"none\", label=\"truth\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(encoder.classes_)\n",
    "ax.set_title(r\"SVM WITHOUT data scaling (on test set)\")\n",
    "ax.legend()\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984a412-6052-473e-ae8f-ec2026a7c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a prediction but on full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "colors = \"ryb\"  # red yellow blue\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for j in range(3): # 3 species\n",
    "    idx = np.where(Y == j)\n",
    "    ax.scatter(X[idx, 0], X[idx, 1], c=colors[j], edgecolor=\"k\", \n",
    "               s=16, label=encoder.classes_[j])\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X_train,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5, 1.5],  # because the labels are 0 1 2\n",
    ")\n",
    "ax.set_xlabel(f\"{feature_names[0]}\"); ax.set_ylabel(f\"{feature_names[1]}\");\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b6028-6490-4e53-8a2d-fd98451a565b",
   "metadata": {},
   "source": [
    "So somehow it finds a boundary for `Chinstraps` to be absolutely tiny to the point it basically doesn't exist, so it makes no predictions for it. Lets see what happens if we standardise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe269d1c-a3d5-4ecb-98ff-5b97ecf0a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise data X the proceed as usual\n",
    "\n",
    "X = df[feature_names].values\n",
    "X = StandardScaler().fit_transform(X) # don't need to do Y\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)\n",
    "\n",
    "# fit a model\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "print(\" \")\n",
    "\n",
    "# plot out the predictions (circles should lie on top of crosses if completely correct)\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = plt.axes()\n",
    "ax.plot(Y_pred, 'bx', label=\"predictions\")\n",
    "ax.plot(Y_test, 'ro', fillstyle=\"none\", label=\"truth\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(encoder.classes_)\n",
    "ax.set_title(r\"SVM with data scaling (on test set)\")\n",
    "ax.legend()\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ce723-15ed-4584-9f35-ff18c78473ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a prediction but on SCALED full data\n",
    "Y_pred = model.predict(X)\n",
    "\n",
    "colors = \"ryb\"  # red yellow blue\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for j in range(3): # 3 species\n",
    "    idx = np.where(Y == j)\n",
    "    ax.scatter(X[idx, 0], X[idx, 1], c=colors[j], edgecolor=\"k\",\n",
    "               s=16, label=encoder.classes_[j])\n",
    "DecisionBoundaryDisplay.from_estimator(model, X,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    ax=ax,\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    alpha=0.3,\n",
    ")\n",
    "DecisionBoundaryDisplay.from_estimator(model, X,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\",\n",
    "    ax=ax,\n",
    "    alpha=1.0,\n",
    "    levels=[0.5, 1.5],  # because the labels are 0 1 2\n",
    ")\n",
    "ax.set_xlabel(f\"scaled {feature_names[0]}\"); ax.set_ylabel(f\"scaled {feature_names[1]}\");\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f0ac2-b785-4798-a15f-b97f95ba64c2",
   "metadata": {},
   "source": [
    "So here it is at least the separators are carving out a region for predicting `Chinstraps`, although the accuracy is not that high.\n",
    "\n",
    "What if we throw all the data in? We can evalute the scores although we can't really plot the bondaries anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ef09a-8007-4be7-93ce-1b22592ee820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as above but for all features\n",
    "feature_names = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = df[feature_names].values\n",
    "X = StandardScaler().fit_transform(X) # don't need to do Y\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4167)\n",
    "\n",
    "# fit a model\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# basic skill diagnostics\n",
    "Y_pred = model.predict(X_test)\n",
    "N = len(Y_test)\n",
    "skill_all = np.sum(Y_pred == Y_test)\n",
    "print(f\"overall skill: {skill_all} correct out of {N} ({skill_all/N*100:.2f}%)\")\n",
    "print(\" \")\n",
    "\n",
    "# plot out the predictions (circles should lie on top of crosses if completely correct)\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = plt.axes()\n",
    "ax.plot(Y_pred, 'bx', label=\"predictions\")\n",
    "ax.plot(Y_test, 'ro', fillstyle=\"none\", label=\"truth\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(encoder.classes_)\n",
    "ax.set_title(r\"SVM with data scaling (on test set)\")\n",
    "ax.legend()\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ea6dc-8b35-48e4-bbb6-8604a53f9820",
   "metadata": {},
   "source": [
    "> <span style=\"color:red\">Q.</span> There is something to be said about decreasing the complexity by minimising the number of features. Consider keep the number of input features at two, but see which combination gives the best score.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> As above, but what if you do dimension reduction techniques on it first?\n",
    "> \n",
    "> <span style=\"color:red\">Q.</span> Try other options under SVM, and/or types of classifers (with various options).\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Do robustness tests and cross-validation accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab8da0-0935-457d-ae27-c6c13c33d041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f8895c8-6338-46df-aa02-6f2383920c78",
   "metadata": {},
   "source": [
    "----------------\n",
    "# More involved exercises with this notebook\n",
    "\n",
    "## 1) Other classifiers\n",
    "\n",
    "There are other classifiers I didn't go through because they either follow the same principles we have encountered before, or they are completely different (e.g. dealing quite a bit with probability). These include:\n",
    "\n",
    "* Ridge classification ($L^2$ penalisation as in linear models; can also do regression)\n",
    "* Logistic classification (it's called `LogisticRegression` in `sklearn` though; it is part of `linear_model`, and is a special case of Generalised Linear Models)\n",
    "* Nearest Neighbours (somewhat related to clustering things we have seen; can also do regression)\n",
    "* Gaussian Processes (probabilistic classifiers; can also do regression)\n",
    "* Naive Bayes and its extensions (as above)\n",
    "\n",
    "Have a look at some of these.\n",
    "\n",
    "(I personally think the Gaussian Processes and Bayesian approaches are the most interesting, because they can provide soft boundaries and measures of uncertainty. I guess just using them is fine, but understanding what they do with take a bit more work.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cc9a0-b8fc-475a-8d04-f1b4edc7805b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab159ed9-caf8-4f46-9745-9f62696e5738",
   "metadata": {},
   "source": [
    "## 2) Classifying cats and dogs\n",
    "\n",
    "#### (This one is related to the upcoming assignment.) \n",
    "\n",
    "Try and do cats and dogs classification. You may or may not want to use dimension reduction approaches first.\n",
    "\n",
    "You may also want to revisit again after all the subsequent lectures (decision trees, random forests, neural networks), because it's a hard test in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ce21d-a8fe-4db5-87cb-f751dc7266b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ba34e7b-7c6c-4121-a985-0a67799df08d",
   "metadata": {},
   "source": [
    "## 3) More with SVM\n",
    "\n",
    "You can use `svm.SVR` for doing regression, try that with some previous examples encountered.\n",
    "\n",
    "There are also other variants of SVM (`NuSVC` and `NuSVR`), have a look and see what those are, apply them to some examples considered here and see how the results compare accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc73d9d-e3f2-4dbe-b22b-02f500b92671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484f8418-d7de-4b82-b3d9-ac9449c984eb",
   "metadata": {},
   "source": [
    "## 4) Regression\n",
    "\n",
    "You can do regression with the SGD stuff too. Have a look on the manual on what kind of loss functions you can use etc. and apply them to some examples considered here or previously also (e.g. penguins data, time series forecasting with `elnino34_sst.data`, Lotka-Volterra, Lorenz, or similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7297ef1-2b26-46e9-874e-542b585d7bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

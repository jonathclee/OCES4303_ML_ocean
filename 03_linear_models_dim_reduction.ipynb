{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a937b507-25cd-470c-aff9-6585667c880f",
   "metadata": {
    "id": "a937b507-25cd-470c-aff9-6585667c880f"
   },
   "source": [
    "*updated 29 Jul 2025, Julian Mak (whatever with copyright, do what you want with this)\n",
    "\n",
    "### As part of material for OCES 4303 \"AI and Machine Learning in Marine Science\" delivered at HKUST\n",
    "\n",
    "For the latest version of the material, go to the public facing [GitHub](https://github.com/julianmak/OCES4303_ML_ocean) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ebc25-e83c-4a4b-a4c5-773ac336db56",
   "metadata": {
    "id": "6b0ebc25-e83c-4a4b-a4c5-773ac336db56"
   },
   "source": [
    "---\n",
    "# 3. Linear models and dimension reduction\n",
    "\n",
    "Going to start with (multi-)linear models, which includes linear regression as a special case. As a recap, given multiple features $X = (X^{(1)}, X^{(2)}, \\ldots)$ (denoted with superscripts, this is different to data sample which I denote by subscripts) and a **single** target $Y$, a linear model is of the form\n",
    "\\begin{equation*}\n",
    "    \\hat{Y} = a_0 + a_1 X^{(1)} + a_2 X_{(2)} + \\ldots a_N X^{(N)}\n",
    "\\end{equation*}\n",
    "where the ***model parameters*** or ***loading values*** are $\\{a_0, a_1, \\ldots, a_N\\}$. The name of the game is find the set of $\\{a_j\\}$ values to minimise a some ***objective/cost/loss function*** $J$ to be specified: the different linear models basically differ in the choice of $J$, which leads to slightly different properties.\n",
    "\n",
    "Given multiple features $X = (X^{(1)}, X^{(2)}, \\ldots)$, you could also ask the question whether you really need all of it, or is a subset or some combination of them enough to provide model skill. This would be ***dimension reduction***, of which PCA is one methodology, and is closely related to ***feature identification***.\n",
    "\n",
    "> ## Key Objective(s)\n",
    "> 1. Explore the properties of a subset of linear models.\n",
    "> 2. Further demonstrate the inbuilt `sklearn` cross-validation routines.\n",
    "> 3. Explore some dimension reduction techniques.\n",
    "\n",
    "Going to load a whole load of basic things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4dd3c7-126c-46a4-9c05-52e0b5336470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd0f84-64a0-4183-a152-22fb2afbd091",
   "metadata": {
    "id": "99bd0f84-64a0-4183-a152-22fb2afbd091"
   },
   "source": [
    "---\n",
    "## a) Linear models\n",
    "\n",
    "Suppose we take a loss function of the form\n",
    "\\begin{equation*}\n",
    "    J = \\frac{1}{2M}\\|\\hat{Y} - Y\\|_{L^2}^2 + \\alpha\\rho\\|a\\|_{L^1} + \\frac{\\alpha(1-\\rho)}{2}\\|a\\|_{L^2}^2,\n",
    "\\end{equation*}\n",
    "made up of the mismatch and two penalisations of the value of the loading values (or control variables). The four variants we are considering here are:\n",
    "\n",
    "* Standard ***linear regression***, which takes $\\alpha = 0$, i.e. there no penalisation (the value of $M$ is actually irrelevant, but you could take it to be $M=1/2$).\n",
    "* ***Ridge optimisation***, which takes $\\rho=0$ (and $M=1/2$). Then $\\alpha$ becomes a model hyperparameter controlling the strength of penalisation, where the values of the coefficients are not allowed to be too big.\n",
    "* ***Lasso***, which takes $\\rho=1$ (and $M$ is the number of samples). This choice of penalisation promotes **sparsity** in the loading values, i.e. we don't just want their size controlled, we don't even want them if possible.\n",
    "* ***Elastic net***, which is a combination of ridge and lasso, and does both at the same time.\n",
    "\n",
    "All the associated methodologies are done somehow, mostly using gradient descent type methods (see the lectures). It's easier to see what they do by using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a729c-ab17-4f83-87e2-86cacc2a4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe7bea-edcc-4f02-a01c-8999e8384d16",
   "metadata": {
    "id": "b1fe7bea-edcc-4f02-a01c-8999e8384d16"
   },
   "source": [
    "### Demonstration: Basic fitting\n",
    "\n",
    "To compare how the aforementioned linear models function, I am going to use artificial data\n",
    "\\begin{equation*}\n",
    "    Y = X^2 + \\epsilon, \\qquad \\epsilon\\sim\\mathcal{N}(0, \\sigma)\n",
    "\\end{equation*}\n",
    "where $\\epsilon$ is some random noise determined by magnitude of $\\sigma$. Here I don't scale the noise level with $X$, so as $X$ becomes big the effect of noise becomes smaller; however I am not going to take $X$ to be that big. The below shows the data (I am fixing the seed to make sure it is reproducible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e8740-54d7-438e-9afa-c1d98b42b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the artificial data\n",
    "\n",
    "sigma = 0.4\n",
    "n = 100\n",
    "X_vec = np.linspace(0, 4, n)  # including 0 here is potentially problematic, do it anyway...\n",
    "np.random.seed(69)\n",
    "Y = X_vec**2 + sigma * np.random.rand(n)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(X_vec, Y, 'ko', alpha=0.7)\n",
    "ax.set_xlabel(r\"$X$\")\n",
    "ax.set_ylabel(r\"$Y$\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559a489-1300-4202-a749-7e6f0974c9fb",
   "metadata": {
    "id": "d559a489-1300-4202-a749-7e6f0974c9fb"
   },
   "source": [
    "In this case I am not going to standarise the data nor do a train/test split (because this is really for demonstrating the differences in the behaviours in the linear model).\n",
    "\n",
    "In this case we know what the data is so it should be clear that we want a model to return $f = X^2$ to us. However I am going to be perverse and assume I don't actually know that, and instead give it a ton of features and ask the model to find me a best fit of those. The features I am going to choose are $(1, X, X^2, X^3 \\ldots X^{10})$: we would like to see whether we get $a_2 \\approx 1$, and $a_{j\\neq 2} \\approx 0$.\n",
    "\n",
    "To use the linear model formalism I am going to manually create the features via generating an $X$ that looks like\n",
    "\\begin{equation*}\n",
    "    \\begin{pmatrix}\n",
    "        x_0^0 & x_0^1 & x_0^2 & \\cdots & x_0^{10} \\\\\n",
    "        x_1^0 & x_1^1 & x_1^2 & \\cdots & x_1^{10} \\\\\n",
    "        \\vdots & \\vdots & & & \\vdots\\\\\n",
    "        x_{99}^0 & x_{99}^1 & x_{99}^2 & \\cdots & x_{99}^{10}\n",
    "    \\end{pmatrix},\n",
    "\\end{equation*}\n",
    "where $x_i^j$ denotes data at position $i$ raised to the power $j$ ($i$-th sample and $j$-th feature). If you remember from your linear algebra, we are trying to get\n",
    "\\begin{equation*}\n",
    "    \\begin{pmatrix}\n",
    "        x_0^0 & x_0^1 & x_0^2 & \\cdots & x_0^{10} \\\\\n",
    "        x_1^0 & x_1^1 & x_1^2 & \\cdots & x_1^{10} \\\\\n",
    "        \\vdots & \\vdots & & & \\vdots\\\\\n",
    "        x_{99}^0 & x_{99}^1 & x_{99}^2 & \\cdots & x_{99}^{10}\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "        a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_{10}\n",
    "    \\end{pmatrix}\n",
    "    =\n",
    "    \\begin{pmatrix}\n",
    "        y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_{99}\n",
    "    \\end{pmatrix}.\n",
    "\\end{equation*}\n",
    "Notice the problem here the matrices are not square, and we are in the over-determined regime. The shape above is also good for `sklearn` because we want the array in `(n_samples, n_features)`: here we have 100 rows (100 samples), and 11 columns (11 features as degree 10 polynomial + a constant).\n",
    "\n",
    "Just going to use the default options from the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585ae43-aed7-4153-b63d-4d798e30c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input features and do a load of fittings\n",
    "deg = 10\n",
    "X = np.zeros((n, deg+1))\n",
    "for j in range(deg+1):\n",
    "    X[:, j] = X_vec**j\n",
    "\n",
    "lin_reg = LinearRegression().fit(X, Y)\n",
    "ridge = Ridge().fit(X, Y)\n",
    "lasso = Lasso().fit(X, Y)\n",
    "e_net = ElasticNet().fit(X, Y)  # I can't get it to converge but it will return an answer\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "ax.plot(X_vec, Y, 'ko', alpha=0.7, label=\"data\")\n",
    "ax.plot(X_vec, lin_reg.predict(X),\n",
    "        label=f\"lin_reg, MSE = {mean_squared_error(Y, lin_reg.predict(X)):.4f}\")\n",
    "ax.plot(X_vec, ridge.predict(X),\n",
    "        label=f\"ridge,   MSE = {mean_squared_error(Y, ridge.predict(X)):.4f}\")\n",
    "ax.plot(X_vec, lasso.predict(X),\n",
    "        label=f\"lasso,   MSE = {mean_squared_error(Y, lasso.predict(X)):.4f}\")\n",
    "ax.plot(X_vec, e_net.predict(X),\n",
    "        label=f\"e_net,   MSE = {mean_squared_error(Y, e_net.predict(X)):.4f}\")\n",
    "ax.set_xlabel(r\"$X$\")\n",
    "ax.set_ylabel(r\"$Y$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f499b6-b2a7-48a4-9425-e3b2f386be03",
   "metadata": {
    "id": "02f499b6-b2a7-48a4-9425-e3b2f386be03"
   },
   "source": [
    "On mine it says `ElasticNet` did not converge, although as you can see the skill is actually ok.\n",
    "\n",
    "It is of interest also to have a look at the coefficients obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59721a3-f65e-4d32-aad7-d3c6d0e98ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the coefficients of the models or the loading values?\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "ax.bar(np.arange(deg+1), lin_reg.coef_)\n",
    "ax.set_title(\"linear regression\")\n",
    "ax.set_ylabel(r\"$a_j$\")\n",
    "ax.grid()\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "ax.bar(np.arange(deg+1), ridge.coef_)\n",
    "ax.set_title(\"ridge\")\n",
    "ax.grid()\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "ax.bar(np.arange(deg+1), lasso.coef_)\n",
    "ax.set_title(\"lasso\")\n",
    "ax.set_xlabel(r\"deg\")\n",
    "ax.set_ylabel(r\"$a_j$\")\n",
    "ax.grid()\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "ax.bar(np.arange(deg+1), e_net.coef_)\n",
    "ax.set_title(\"elastic net\")\n",
    "ax.set_xlabel(r\"deg\")\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout(pad=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4832a-3c34-4324-9148-42bc94c2ae7e",
   "metadata": {
    "id": "b5a4832a-3c34-4324-9148-42bc94c2ae7e"
   },
   "source": [
    "Several things to notice here:\n",
    "\n",
    "* Linear regression and ridge both use $L^2$ in the loss, and the result model coefficients are noticeably non-zero across the board (smaller in ridge though). This is not seen in Lasso and elastic net, which include a $L^1$ term in the loss.\n",
    "* Ridge is really the only one that predicts the loading in the degree 2 term ($a_2$), although there is loading everywhere else.\n",
    "* Interestingly Lasso predicts a dominant loading at degree 4. This is actually plausible, because for small enough $X$ values (default here being from $0$ to $4$) $X^2$ and $X^4$ can be argued to not be that dissimilar in shape (and could argued to be the case for the other even powers).\n",
    "\n",
    "Below shows how they perform poorly in extrapolation, demonstrating a signficant issue with over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960e6b6-0836-4d12-b0f5-059f567056d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a single extrapolation\n",
    "x0 = 7.0\n",
    "X_extra = np.zeros((1, deg+1))\n",
    "for j in range(deg+1):\n",
    "    X_extra[:, j] = x0**j\n",
    "\n",
    "# compute some errors\n",
    "print(f\"target value at x0         = {x0**2:.4f}\")\n",
    "print(f\"lin_reg extrapolated value = {lin_reg.predict(X_extra)[0]:.6f}\")\n",
    "print(f\"ridge   extrapolated value = {ridge.predict(X_extra)[0]:.6f}\")\n",
    "print(f\"lasso   extrapolated value = {lasso.predict(X_extra)[0]:.6f}\")\n",
    "print(f\"e_net   extrapolated value = {e_net.predict(X_extra)[0]:.6f}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade2273-0e96-4abf-8a1a-02fffe866e4a",
   "metadata": {
    "id": "0ade2273-0e96-4abf-8a1a-02fffe866e4a"
   },
   "source": [
    "> <span style=\"color:red\">Q.</span> See how the above behaviours change if you expand decreasing the training range (e.g. instead of `X_vec = (0, 4)` try `(0, 8)`, or `(4, 8)`, or randomly pick some values to do the model fitting in some specified region etc.)\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Introduce some variability and do an ensemble of fittings (easiest is via `train_test_split`, although you can do the random picking within a region specified above also). Quantify the robustness of the above properties (e.g. do box-plots/histograms over the ensemble of the loading values, errors etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd6870-7826-4f06-aa00-983e0d033574",
   "metadata": {
    "id": "0bdd6870-7826-4f06-aa00-983e0d033574"
   },
   "source": [
    "### Cross-validation again, but done in a more sleek way\n",
    "\n",
    "Now that we have models of sufficient complexity and within the `sklearn` family we could use some in-built tools there to help with cross-validation (although it is good practice to do it once or twice by hand before). Below for example demonstrates $k$-fold cross-validation that differs in the train/test splitting using `ridge` (others have some issues with convergence sometimes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b4aac-81f3-4859-a824-4f91752b8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = Ridge(alpha=1) # initialise but don't fit\n",
    "scores = cross_val_score(model, X, Y, cv=5)  # uses default score of estimator (R^2 here)\n",
    "\n",
    "print(f\"score = {scores}\")\n",
    "print(f\"scores mean accuracy {scores.mean():.2f}\")\n",
    "print(f\"score std {scores.std():.2f}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1d357-d5ca-42a7-b792-4c153a4f6862",
   "metadata": {
    "id": "81b1d357-d5ca-42a7-b792-4c153a4f6862"
   },
   "source": [
    "Without specifying the score of interest it will use the default, which for regression is the $R^2$ score. When I do it there are cases where models are clearly breaking with very large scores...\n",
    "\n",
    "Can randomise it a bit more and be more specific in the choice of scores (see [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) for a list) as follows.\n",
    "\n",
    "> NOTE: You can pass a list of scores in, e.g. `scoring=[\"neg_mean_squared_error\", \"neg_mean_absolute_error\"]`, but the below print commands will need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd77c2-bbbf-4591-b869-1016da1656cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2)               # specify split\n",
    "scores = cross_val_score(model, X, Y, cv=cv,\n",
    "                        scoring=\"neg_mean_squared_error\")  # specify score\n",
    "\n",
    "print(f\"score = {scores}\")\n",
    "print(f\"scores mean accuracy {scores.mean():.2f}\")\n",
    "print(f\"score std {scores.std():.2f}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29708204-d5bc-40fa-8974-052ac46ccde0",
   "metadata": {
    "id": "29708204-d5bc-40fa-8974-052ac46ccde0"
   },
   "source": [
    "These can then be piggybacked for doing model selection and hyperparameter tuning, manually or using other `sklearn` objects. For length reasons I'm going to leave this as an extended exercise instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cac78-506c-4687-8aaa-484101f06efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52af85f6-745b-4441-87fe-f02a86edd255",
   "metadata": {
    "id": "52af85f6-745b-4441-87fe-f02a86edd255"
   },
   "source": [
    "---\n",
    "## b) Dimension reduction (cf. data feature identification)\n",
    "\n",
    "An observation with the above linear model example is that you could in principle get reasonably good model skill without having to have a lot of features (e.g. the $L^1$ penalised models). That's a good thing presumably because that helps in principle in avoiding over-fitting, and it also speeds up the training stage in principle (because you are throwing less data in). Ways to identify the most useful \"features\" for model training/skill is thus of interest: this would be ***dimension reduction*** in that out of the possible space of results allowed by all data, you want to find a useful ***feature space*** that is presumably lower dimenion and less complex than the original space.\n",
    "\n",
    "Asking for the *most* skillful one is probably quite a difficult question to answer. We will instead look for ways to simply find feature spaces that are simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6774f8-1521-4280-92b8-13c7e23edadf",
   "metadata": {
    "id": "4d6774f8-1521-4280-92b8-13c7e23edadf"
   },
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "(Or sometimes Empirical Orthogonal Functions (EOF)s particularly when space dimensions are involved.) This we already encountered in OCES 3301 and is essentially finding linear combinations of the features that maximises the variance explained in the data (again, these are optimisation problems, just with a different choice of loss function).\n",
    "\n",
    "For example, for the `penguins` data, instead of the feature space being `(bill_length, bill_depth, flipper_length, body_mass)`, it could be that (say) `(bill_length + 2 body_mass, flipper_length + body_mass - bill_depth)` actually explains the data the best. This may not make sense scientifically, but that's not the point: PCA only seeks to maximise variance explained, variance is related to correlations, and correlation does not imply causation.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Have a think why there is no real reason to do a PCA as such for the polynomial fitting problem above.\n",
    "\n",
    "Although some of this was already done in OCES 3301, the below is included mostly for completeness.\n",
    "\n",
    "> NOTE: If you know this stuff, then PCA is just a SVD ranked by the magnitude of the singular values. The singular vectors are the features of interest and are orthogonal by construction (hence the O in EOF). When the matrix is squre then this would be a diagnoalisation of covariance matrix in terms of its eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c163a-922b-424d-a6b6-23acf0a7a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load the penguin data\n",
    "option = \"remote\"\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"penguins.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/penguins.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954e353-dd8e-4055-9783-563dc30d8419",
   "metadata": {
    "id": "b954e353-dd8e-4055-9783-563dc30d8419"
   },
   "source": [
    "First going to do simple (and arguably unnecessary) case of two variables to two other variables, in which case we are simply dealing with a co-ordinate transformation.\n",
    "\n",
    "> NOTE: The thing with PCA is that it does depend quite strongly on choice of pre-processing. By default you should do data scaling before you do PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54d39f-a984-4d40-9275-69f54bafda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA of two variables to two other variables (i.e. a co-ordinate transformation)\n",
    "features = ['bill_length_mm', 'bill_depth_mm']\n",
    "X = df[features].values\n",
    "\n",
    "# scale and fit the data\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "# input in scaled space\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "for species in df[\"species\"].unique():   # pick out all unique entries under `species`\n",
    "    ax.scatter(X_scaled[df[\"species\"] == species, 0],\n",
    "               X_scaled[df[\"species\"] == species, 1],\n",
    "               label=species,\n",
    "               alpha=0.5,  # fade this for demonstration later\n",
    "               )\n",
    "ax.annotate(\"\",\n",
    "            pca.mean_ + pca.components_[0] * 2 * np.sqrt(pca.explained_variance_[0]),\n",
    "            pca.mean_,\n",
    "            arrowprops=dict(color=\"green\", arrowstyle='->', linewidth=2, shrinkA=0, shrinkB=0))\n",
    "ax.annotate(\"\",\n",
    "            pca.mean_ + pca.components_[1] * 2 * np.sqrt(pca.explained_variance_[1]),\n",
    "            pca.mean_,\n",
    "            arrowprops=dict(color=\"blue\", arrowstyle='->', linewidth=2, shrinkA=0, shrinkB=0))\n",
    "ax.set_xlabel(f\"scaled {features[0]}\")\n",
    "ax.set_ylabel(f\"scaled {features[1]}\")\n",
    "ax.grid(lw=0.5, zorder=0)\n",
    "ax.legend()\n",
    "\n",
    "# inputs in PCA basis\n",
    "X_pca = pca.transform(X_scaled)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "for species in df[\"species\"].unique():   # pick out all unique entries under `species`\n",
    "    ax.scatter(X_pca[df[\"species\"] == species, 0],\n",
    "               X_pca[df[\"species\"] == species, 1],\n",
    "               label=species,\n",
    "               alpha=0.5,  # fade this for demonstration later\n",
    "               )\n",
    "ax.annotate(\"\",\n",
    "            [2 * np.sqrt(pca.explained_variance_[0]), 0],\n",
    "            [0, 0],\n",
    "            arrowprops=dict(color=\"green\", arrowstyle='->', linewidth=2, shrinkA=0, shrinkB=0))\n",
    "ax.annotate(\"\",\n",
    "            [0, 2 * np.sqrt(pca.explained_variance_[1])],\n",
    "            [0, 0],\n",
    "            arrowprops=dict(color=\"blue\", arrowstyle='->', linewidth=2, shrinkA=0, shrinkB=0))\n",
    "ax.set_xlabel(f\"PC 1 (var explained = {pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC 2 (var explained = {pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.grid(lw=0.5, zorder=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e9e4b-a766-4f8d-a1af-c2a499fa4dfc",
   "metadata": {
    "id": "ae9e9e4b-a766-4f8d-a1af-c2a499fa4dfc"
   },
   "source": [
    "Above looks like a rotation, a flip about the axis defined defined by the blue arrow, and then some mild scaling to me.\n",
    "\n",
    "A more interesting case is if I dump everything in, which would be a reduction of four dimensions to two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aac29e-747a-4b4f-807b-c72ff18db271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw everything into the PCA (in this case ignore species)\n",
    "features = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = df[features].values\n",
    "\n",
    "# scale data, fit PCA (do 2 componens here), transform data\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = plt.axes()\n",
    "for species in df[\"species\"].unique():   # pick out all unique entries under `species`\n",
    "    ax.scatter(X_pca[df[\"species\"] == species, 0],\n",
    "               X_pca[df[\"species\"] == species, 1],\n",
    "               label=species,\n",
    "               alpha=0.5,  # fade this for demonstration later\n",
    "               )\n",
    "ax.set_xlabel(f\"PC 1 (var explained = {pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "ax.set_ylabel(f\"PC 2 (var explained = {pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "ax.grid(lw=0.5, zorder=0)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9dceba-7f52-402a-b16b-544ae3d4cc35",
   "metadata": {
    "id": "cf9dceba-7f52-402a-b16b-544ae3d4cc35"
   },
   "source": [
    "Note the percentages in this case do not sum to 100%, because we have discarded two dimensions. We can query the percentages and also the feature combinations as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf3cd6-59f2-4e23-9aa8-986ee5723e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to screen the percentages and PC constituents\n",
    "\n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    print(f\"PC {i+1} explains {pca.explained_variance_ratio_[i]*100:.2f}% of variance\")\n",
    "print(\" \")\n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    print(f\"\"\"PC {i+1} = {pca.components_[i, 0]:.4f} * {features[0]} +\n",
    "       {pca.components_[i, 1]:.4f} * {features[1]} +\n",
    "       {pca.components_[i, 2]:.4f} * {features[2]} +\n",
    "       {pca.components_[i, 3]:.4f} * {features[3]}\"\"\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603265b-e33c-45b7-9f69-54798fecd885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543bbcb2-a76e-4b7e-ad18-246f2a2c1529",
   "metadata": {
    "id": "543bbcb2-a76e-4b7e-ad18-246f2a2c1529"
   },
   "source": [
    "### Locally linear embedding and $t$-SNE\n",
    "\n",
    "The next two we are only going to skim briefly, but they will come back next lecture when we talk about ***clustering***.\n",
    "\n",
    "The original paper to ***Locally Linear Embedding*** is [here](https://www.science.org/doi/10.1126/science.290.5500.2323). This you can think of as PCAs done locally, and these local regions are patched together to form a best fit global reduction. Below just demonstrates how these are used and the result on the penguin data, although it may make more sense after next lecture with a better example where it will significantly affect the results from clustering.\n",
    "\n",
    "> NOTE: This I think is a bit like in differential geometry where you find a whole load of local co-ordinate charts, and then patch it up to find a good global atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec968c-c999-45b4-84e1-171ea585ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "features = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = df[features].values\n",
    "\n",
    "lle = LocallyLinearEmbedding()  # default of 2 components (so 2 dimensions)\n",
    "X = StandardScaler().fit_transform(X)  # comment to switch of scaling if wanted\n",
    "X_lle = lle.fit_transform(X)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "for species in df[\"species\"].unique():   # pick out all unique entries under `species`\n",
    "    ax.scatter(X_lle[df[\"species\"] == species, 0],\n",
    "               X_lle[df[\"species\"] == species, 1],\n",
    "               label=species,\n",
    "               alpha=0.5,  # fade this for demonstration later\n",
    "               )\n",
    "ax.set_xlabel(r\"$\\tilde{X}_1$\")\n",
    "ax.set_ylabel(r\"$\\tilde{X}_2$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bfa00-1020-4f4b-ae07-71a3154113b6",
   "metadata": {
    "id": "882bfa00-1020-4f4b-ae07-71a3154113b6"
   },
   "source": [
    "This seems to suggest there is a projection that can strongly separate out the Gentoo penguins from others, which may help in classification tasks for example.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> The default option above is `standard`, but there are other options that can be specified (e.g. `ltsa`, `hessian`, `modified`). See [here](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html#sklearn.manifold.LocallyLinearEmbedding) for what those mean and try a few of those out. Might also be good to revisit this in the next lecture.\n",
    "\n",
    "***$t$-distributed Stochastic Neighbor Embedding*** ($t$-SNE) tries to do something similar but instead assigns how close data is in the original space by Gaussian probabilities, and the closeness in the transformed space by Student $t$-distributions (cf. `05_hypothesis_testing` in OCES 3301), and together aids in looking for a projection that is sensitive to local data structures. While the former method is better for continuously distributed samples, the method here might be better for local samples.\n",
    "\n",
    "> NOTE: $t$-SNE can be slow.\n",
    ">\n",
    "> The default has `TSNE(init=\"pca\")`, which helps with stability. `init=\"random\"` is the other option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be5220-dc24-4612-8d1a-28e7b30b3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "features = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = df[features].values\n",
    "\n",
    "tsne = TSNE()  # default of 2 components (so 2 dimensions)\n",
    "X = StandardScaler().fit_transform(X)  # comment to switch of scaling if wanted\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = plt.axes()\n",
    "for species in df[\"species\"].unique():   # pick out all unique entries under `species`\n",
    "    ax.scatter(X_tsne[df[\"species\"] == species, 0],\n",
    "               X_tsne[df[\"species\"] == species, 1],\n",
    "               label=species,\n",
    "               alpha=0.5,  # fade this for demonstration later\n",
    "               )\n",
    "ax.set_xlabel(r\"$\\tilde{X}_1$\")\n",
    "ax.set_ylabel(r\"$\\tilde{X}_2$\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c6586-63f2-4bbc-888f-1018450c3c27",
   "metadata": {
    "id": "835c6586-63f2-4bbc-888f-1018450c3c27"
   },
   "source": [
    "So note here that we get fairly well separated clusters of points (with a little bit of mixing between Adelie and Chinstrap), which will presumably aid in clustering and/or classification tasks.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Switch off data standardisation and see what happens. Is this expected?\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Change over to `init=\"random\"` and see how the clustering changes. You may want to run multiple instances to check for robustness and/or wellness of separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6faf1-47d3-4b02-bedc-c4fe18393a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e76ced1-6d78-486f-82b6-a7d54dcbf9d8",
   "metadata": {
    "id": "5e76ced1-6d78-486f-82b6-a7d54dcbf9d8"
   },
   "source": [
    "---\n",
    "## c) Demonstration: Eigencat\n",
    "\n",
    "A fun application of PCA would be the [eigenpets](https://bioramble.wordpress.com/2015/09/01/pca-part-5-eigenpets/) example (cf. [eigenfaces](https://en.wikipedia.org/wiki/Eigenface)). Given a collection of cat images, what is the \"pattern\" that explains most of the variance? This has uses in things like image/facial recognition: you might imagine certain species of cats have a particular signature in some modes. More generally, this might be useful in ***classification*** tasks where you are trying to identify species and the like. Having these features may also be helpful for reconstruction of broken images.\n",
    "\n",
    "The idea is quite simple: instead of a set of images being `(n_samples, width, height)`, we simply reshape/flatten it into `(n_samples, pixels)`; this is what was done for computing EOFs in OCES 3301. Then you dump it into the PCA routine as usual. We first have a load and plot out some of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e74c-7e95-447c-ab66-40e8a27a348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't read the headers\n",
    "\n",
    "option = \"remote\"\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"cat.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/cat.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df = pd.read_csv(path, header=None).T # make \"features\" the axis=-1\n",
    "X = df.values\n",
    "print(f\"data array shape is {X.shape}\")\n",
    "print(\" \")\n",
    "\n",
    "# generate a list of 25 indices (generate full list, shuffle, select first 25, so no repeats)\n",
    "ind = np.arange(80)\n",
    "np.random.shuffle(ind)  # syntax for shuffle: not used like a function with input output...\n",
    "\n",
    "# sample show (on-the-fly reshape data)\n",
    "fig = plt.figure(figsize=(8, 8.5))\n",
    "for i in range(25):\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    ax.imshow(np.reshape(X[ind[i], :], (64, 64)).T, cmap=\"gray\")\n",
    "    ax.set_title(f\"#{ind[i]}\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372af57-d85f-45ff-9937-6e4b76adc2cb",
   "metadata": {
    "id": "5372af57-d85f-45ff-9937-6e4b76adc2cb"
   },
   "source": [
    "So here the raw data has already been flattened and is in the right shape (otherwise just transpose it with `.T`). We will PCA it accordingly, but I won't standardise it in this case (though probably should to remove the mean).\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Have a think why I made that choice, and possibly investigate later what consequences you may have if you do standardise in the usual way (uncomment two of the lines below), or with other choices of standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jBFerjgZNwbZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf06f3-e1ca-44d9-80bc-e5fae40fbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data, fit and transform PCA (do 40 componens for the hell of it)\n",
    "# scale = StandardScaler()\n",
    "# X = scale.fit_transform(X) # if standardising in cell above then images are less sharp (Q: why?)\n",
    "pca = PCA(n_components=40)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# should be (n_EOF, pixels)\n",
    "print(f\"PCA components with shape {pca.components_.shape}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba14882-e8c5-4da5-a67f-53d7c0939f0c",
   "metadata": {
    "id": "bba14882-e8c5-4da5-a67f-53d7c0939f0c"
   },
   "source": [
    "The transformed data should be in `(n_EOF, pixels)` in this case. We can reshape and plot them out accordingly.\n",
    "\n",
    "Note that I am calling the patterns the EOFs, while the loading I am going call the PCs (really I would call them the singular vectors and the coefficients). In this case the mathematical expresion might be less ambiguous:\n",
    "\\begin{equation*}\n",
    "    \\mathrm{Image}(\\mathrm{pixels}) = \\sum_i \\mbox{PC}_i \\times \\mbox{EOF}_i(\\mathrm{pixels}),\n",
    "\\end{equation*}\n",
    "and each image differs in the $\\mbox{PC}_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454abbd-53b1-43cc-8067-5ccfc56db960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigencats\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "for i in range(15):\n",
    "    ax = plt.subplot(3, 5, i+1)\n",
    "    ax.imshow(np.reshape(pca.components_[i, :], (64, 64)).T, cmap=\"gray\")\n",
    "    ax.set_title(f\"var = {pca.explained_variance_ratio_[i] * 100:.2f}%\")\n",
    "    ax.set_ylabel(f\"EOF {i+1}\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5797d-36f8-40c2-892a-d54c383b1eef",
   "metadata": {
    "id": "dbd5797d-36f8-40c2-892a-d54c383b1eef"
   },
   "source": [
    "Some observations:\n",
    "\n",
    "* Here you might think EOF1 probably measures colour: if the associated PC1 is positive then we are dealing with lighter coloured cats probably, and vice-versa for negative PC1s.\n",
    "* EOF2 and 3 might be about facial patterns.\n",
    "* EOF4 and 5 might be about \"chubby-ness\" of face?\n",
    "* Extra details on the later patterns.\n",
    "\n",
    "These are all speculations of course, because again PCA is statistical and only finds the correlations, whereas it is me who attributes the causality.\n",
    "\n",
    "Below are some selected examples of cats with increasing numbers of EOFs added, i.e. I am doing\n",
    "\\begin{equation*}\n",
    "    \\mathrm{Reconstructed\\ Image}(\\mathrm{pixels}) \\approx \\sum_i^m \\mbox{PC}_i \\times \\mbox{EOF}_i(\\mathrm{pixels})\n",
    "\\end{equation*}\n",
    "with increasing $m$. I am also going to plot out the corresponding loading values $\\mbox{PC}_i$ as a graph for the selected samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf690a8-5605-4e09-8fcc-1f31ca497fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample decomposition (X_pca above is the PC)\n",
    "\n",
    "cat_num = [33, 44, 61]\n",
    "pca_ind = [5, 10, 20, 30, 40]\n",
    "\n",
    "# do some plots to show decomposition\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(3):\n",
    "    cat_ind = cat_num[j]\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 6, (j*6)+i+1)\n",
    "        # plot original image\n",
    "        if i % 6 == 0:\n",
    "            ax.imshow(np.reshape(X[cat_ind, :], (64, 64)).T, cmap=\"gray\")\n",
    "            ax.set_title(f\"#{cat_num[j]}\")\n",
    "        # plot the reconstruction with increasing number of PCs\n",
    "        else:\n",
    "            # sum to get (scaled) reconstruction via sum_i (PC_i * EOF_i)\n",
    "            ind = pca_ind[i-1]\n",
    "            dum = np.sum(X_pca[cat_ind, :ind] * pca.components_[:ind, :].T, axis=-1)\n",
    "            ax.imshow(np.reshape(dum, (64, 64)).T, cmap=\"gray\")\n",
    "            ax.set_title(f\"to EOF = {pca_ind[i-1]}\")\n",
    "            count += 1\n",
    "\n",
    "        ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6kOQN_0TNd9V",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the shape !!\n",
    "print('Shape of X: ', X.shape)\n",
    "print(\"Shape of X_pca: \", X_pca.shape)\n",
    "print(\"Shape of EOFs: \", pca.components_.shape)\n",
    "# reconstruction is sth similar to this (add mean for reverse shifting / centering)\n",
    "X_recon = np.dot(X_pca, pca.components_) + pca.mean_[np.newaxis, :]\n",
    "print(\"Matrix multi, Shape(X_pca * EOFs) = \", (X_recon).shape)\n",
    "\n",
    "# wont be able to exactly reconstruct the original images, try plotting to see\n",
    "# plt.imshow(np.reshape(X[0, :], (64, 64)).T, cmap=\"gray\")\n",
    "# plt.imshow(np.reshape(X_recon[0, :], (64, 64)).T, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d20ea3-a9ef-4222-9600-496e7becd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the PC decomposition\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = plt.axes()\n",
    "for cat in cat_num:\n",
    "    ax.plot(np.arange(1, X_pca.shape[-1]+1), X_pca[cat, :], label=f\"cat #{cat}\")\n",
    "ax.set_xlabel(\"PC\"); ax.set_ylabel(\"magnitude\")\n",
    "ax.grid()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73c6b9-a735-4968-9b2d-2ef533114a00",
   "metadata": {
    "id": "db73c6b9-a735-4968-9b2d-2ef533114a00"
   },
   "source": [
    "Perhaps as expected we see that the black and white cat differs primarily in PC1. The tabby cat has a different signature on the other hand. This may aid in the classification of images via a machine learning algorithm in the following ways:\n",
    "\n",
    "* The different signatures might be distinguishing feature that allows separation of labels (see Lec 05 when we talk about classification tasks).\n",
    "* Instead of throwing the above images (which is $64^2 = 4096$ features, i.e. high dimension space), we are instead doing learning in a much lower dimension space (in this case 40), which may be good in mitigation of over-fitting.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> I am plotting the eigenpets Here I am plotting the SCALED images. You can consider unscale them by `scale.inverse_transform(pca.components_)` say, but then something a bit weird happens. See what that is, and see if you have an explanation for this.\n",
    "\n",
    "### A fun demonstration and also a warning\n",
    "\n",
    "I am going to go nuts and load an even larger dataset and do the same thing. Here I am going to do a PCA with 2000 components (again not standardising). This takes a bit of time (no more than 10 seconds on my laptop, around 20 seconds in Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2085d-83d9-48c4-aa3a-32fcf4b5ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2000 images here; data ordering with the same convention\n",
    "option = \"remote\"\n",
    "\n",
    "if option == \"local\":\n",
    "    print(\"loading data locally (assumes file has already been downloaded)\")\n",
    "    path = \"cat_bw_enlarged.csv\"\n",
    "elif option == \"remote\":\n",
    "    print(\"loading data remotely\")\n",
    "    path = \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/cat_bw_enlarged.csv\"\n",
    "else:\n",
    "    raise ValueError(\"INVALID OPTION: use 'remote' or 'local'\")\n",
    "\n",
    "df = pd.read_csv(path, header=None).T # make \"features\" the axis=-1\n",
    "X = df.values\n",
    "\n",
    "# scale data, fit PCA, transform data\n",
    "pca = PCA(n_components=2000)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44289f6-f9e8-4f0a-81b3-a10b8ee0f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded eigencats\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "for i in range(15):\n",
    "    ax = plt.subplot(3, 5, i+1)\n",
    "    ax.imshow(np.reshape(pca.components_[i, :], (64, 64)).T, cmap=\"gray\")\n",
    "    ax.set_title(f\"var = {pca.explained_variance_ratio_[i] * 100:.2f}%\")\n",
    "    ax.set_ylabel(f\"EOF {i+1}\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc10e0-9607-47f4-bb69-7ba9a07cb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample decomposition (X_pca above is the PC)\n",
    "\n",
    "cat_num = [2, 5, 31]\n",
    "pca_ind = [50, 100, 200, 500, 1000]\n",
    "\n",
    "# do some plots to show decomposition\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(3):\n",
    "    cat_ind = cat_num[j]\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 6, (j*6)+i+1)\n",
    "        # plot original image\n",
    "        if i % 6 == 0:\n",
    "            ax.imshow(np.reshape(X[cat_ind, :], (64, 64)).T, cmap=\"gray\")\n",
    "            ax.set_title(f\"#{cat_num[j]}\")\n",
    "        # plot the reconstruction with increasing number of PCs\n",
    "        else:\n",
    "            # sum to get (scaled) reconstruction via sum_i (PC_i * EOF_i)\n",
    "            ind = pca_ind[i-1]\n",
    "            dum = np.sum(X_pca[cat_ind, :ind] * pca.components_[:ind, :].T, axis=-1)\n",
    "            ax.imshow(np.reshape(dum, (64, 64)).T, cmap=\"gray\")\n",
    "            ax.set_title(f\"to EOF = {pca_ind[i-1]}\")\n",
    "            count += 1\n",
    "\n",
    "        ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d7d65-3afb-48c5-a269-b9c82f1421a6",
   "metadata": {
    "id": "b53d7d65-3afb-48c5-a269-b9c82f1421a6"
   },
   "source": [
    "So notice that this larger dataset is not as clean in that we have cat images that are\n",
    "\n",
    "* Missing features (the first one isn't showing the ears)\n",
    "* Not centred (includes whole fact but rotated somewhat)\n",
    "* Not focused (showing whole body as well as other presumably irrelevant features)\n",
    "\n",
    "By enlarging the dataset with extra details I am massively increasing the dimension and extent of my feature space, which may or may not be a good thing. With this I can fit whatever I like to the trained set, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x-SdN_e4-30O",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# temp. download image copies to google colab, to cwd\n",
    "cwd = os.getcwd()\n",
    "print(\"Current cwd: \", cwd)\n",
    "\n",
    "targets_path = {\n",
    "    \"miffy_gormless\" : \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/miffy_gormless.jpg\",\n",
    "    \"blauhaj\" : \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/blauhaj.jpg\",\n",
    "    \"clippy\" : \"https://raw.githubusercontent.com/julianmak/OCES4303_ML_ocean/refs/heads/main/clippy.jpg\",\n",
    "}\n",
    "\n",
    "for file_name, file_url in targets_path.items():\n",
    "  response = requests.get(file_url)\n",
    "  with open(cwd + \"/\" + file_name+'.jpg', \"wb\") as f:\n",
    "      f.write(response.content)\n",
    "  print(f\"File downloaded to: {cwd + '/' + file_name+'.jpg'}\")\n",
    "\n",
    "# jpg downloaded to /content, which is the cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff4fce-aabd-40a7-a127-6a189bc2a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit some doofuses\n",
    "targets = [\"miffy_gormless\", \"blauhaj\", \"clippy\"]\n",
    "pca_ind = [50, 100, 200, 1000, 2000]\n",
    "\n",
    "# do some plots to show decomposition\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(3):\n",
    "    X = plt.imread(f\"{targets[j]}.jpg\").T.flatten()\n",
    "    X_pca = pca.transform(X.reshape(1, -1))\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 6, (j*6)+i+1)\n",
    "        # plot original image\n",
    "        if i % 6 == 0:\n",
    "            ax.imshow(np.reshape(X, (64, 64)).T, cmap=\"gray\")\n",
    "            if j == 0:\n",
    "                ax.set_title(\"orig\")\n",
    "        # plot the reconstruction with increasing number of PCs\n",
    "        else:\n",
    "            # sum to get (scaled) reconstruction via sum_i (PC_i * EOF_i)\n",
    "            ind = pca_ind[i-1]\n",
    "            dum = np.sum(X_pca[0, :ind] * pca.components_[:ind, :].T, axis=-1)\n",
    "            ax.imshow(np.reshape(dum, (64, 64)).T, cmap=\"gray\")\n",
    "            ax.set_title(f\"to EOF = {pca_ind[i-1]}\")\n",
    "            count += 1\n",
    "\n",
    "        ax.set_xticks([]); ax.set_yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64daea6a-9447-42bf-a42e-ef5ba82a0032",
   "metadata": {
    "id": "64daea6a-9447-42bf-a42e-ef5ba82a0032"
   },
   "source": [
    "With the expanded set I can fit:\n",
    "\n",
    "* A cat that wasn't in the sample\n",
    "* An animal that's not a cat\n",
    "* Not even an animal\n",
    "\n",
    "The first is good but the latter are not. You can imagine I train a classifier, then it might identify the bottom one as a \"siamese cat\".\n",
    "\n",
    "A take home message here may be that more data is not always good: it does expand the sampled pdf, but it also allows for more possibility of hallucinations with the extra complexity. Just like \"practice makes perfect\" is really \"PERFECT practice makes perfect\", we should really have \"more GOOD data is good\".\n",
    "\n",
    "> NOTE: There are of course data choices that can be used to mitigate these hallucinations (a simple one would be to add `not cat` labels). There are also model design choices that can be taken as well, but those will be beyond the scope of this course.\n",
    "\n",
    "> <span style=\"color:red\">Q.</span> Exercise in data processing: Find your favourite image and try and see if you can use the expanded eigenpets with it.\n",
    ">\n",
    "> <span style=\"color:red\">Q.</span> Consider doing locally linear embedding or $t$-SNE instead of PCA. Probably don't do it on the extended cat set particularly with $t$-SNE, because that will probably kill your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133a48e-7053-44cb-a3e7-9d314a57cd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36dd3829-3f11-4514-96b0-8a37547bb9ab",
   "metadata": {
    "id": "36dd3829-3f11-4514-96b0-8a37547bb9ab"
   },
   "source": [
    "----------------\n",
    "# More involved exercises with this notebook\n",
    "\n",
    "## 1) Polynomial regression\n",
    "\n",
    "Consider doing polynomial regression using `sklearn.preprocessing.PolynomialFeatures`; this might be easier with [`pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) also. I basically did it manually above.\n",
    "\n",
    "(Essentially choosing a [basis for the features](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions), and is related to what we would do with [SINDy](https://pysindy.readthedocs.io/en/latest/), which we may visit in the bonus material.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97741a24-3b45-4ac2-b69b-8871e62c08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdeb845-ddbe-4f5a-bc3d-46b784aecc87",
   "metadata": {
    "id": "4bdeb845-ddbe-4f5a-bc3d-46b784aecc87"
   },
   "source": [
    "## 2) Generalised Linear Models (GLMs)\n",
    "\n",
    "Have a look at [GLMs](https://scikit-learn.org/stable/modules/linear_model.html#generalized-linear-models), and try applying this in some of the examples above (or make up / apply to your own synthetic/real examples).\n",
    "\n",
    "(The reason we don't touch this is because this requires you knowing more things about other probability distribution funtcions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee7be1-77e5-46ba-85fb-640dc6945459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc012ff-3716-4bd2-b2a1-2b755f897cbd",
   "metadata": {
    "id": "9dc012ff-3716-4bd2-b2a1-2b755f897cbd"
   },
   "source": [
    "## 3) Bayesian regression\n",
    "\n",
    "Have a look at [Bayesian regession](https://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression), and try applying this in some of the examples above (or make up / apply to your own synthetic/real examples).\n",
    "\n",
    "(The reason we don't touch this is because this requires you knowing the Bayesian formalism of probability/statistics.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9a04f-3fd0-40ac-892d-16432c5b361b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c884cb9-8e77-4103-8bb3-cc8b0ce82b5d",
   "metadata": {
    "id": "9c884cb9-8e77-4103-8bb3-cc8b0ce82b5d"
   },
   "source": [
    "## 4) Predicting cat faces, and on model interpretability\n",
    "\n",
    "Going to the raw images of cats, consider training linear models of the above ilk on half the face and using it to predict the other half. Analyse the skill on training data, testing data, the need for standardising the data, analysis of the model coefficients, dependence on the propotion of face exposed to model, cross-validation and etc.\n",
    "\n",
    "From a coding point of view it is potentially easier to use the left half of the face to predict the right half (idea below). You can try top and bottom also.\n",
    "\n",
    "<img src=\"https://i.imgur.com/G7xJJvu.jpeg\" width=\"500\" alt='cursed prediction'>\n",
    "\n",
    "One interest here is in the model coefficients: the loading values would provide a suggestion on which pixels may matter the most in the training of the model for the prediction problem, which aids in ***interpretability*** of the model. We will come back to do this when we get to `07_Neural_Networks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa621e-4c87-48a0-b6d8-6a3205a151a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a3ba38-5e5f-45e6-8ee1-868fac1a4cf0",
   "metadata": {
    "id": "a2a3ba38-5e5f-45e6-8ee1-868fac1a4cf0"
   },
   "source": [
    "## 5) Classification tasks and eigenpets\n",
    "\n",
    "We will come back to this in `05_classification`. There is the analogous dog data called `dog.csv`; try and do an eigenpets decomposition say.\n",
    "\n",
    "Then have a think how you might do classification of an image based on the features generated from eigenpets, and try and do that if you want to. One way to do it is simply say $Y=1$ is cat and $Y=-1$ is dog or analogously (i.e. you label the data), then you train a linear model based on the image and/or the eigenpet features. The predicted values will not be exactly $1$ or $-1$, but then you only need the sign of it (e.g. if predicted value is positive then it is a cat, and vice-versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec0d51-c8b4-4a86-8eb1-deb8daf42570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "588d1795-3068-429c-a4ff-6348ec4919d9",
   "metadata": {
    "id": "588d1795-3068-429c-a4ff-6348ec4919d9"
   },
   "source": [
    "## 6) Argo data\n",
    "\n",
    "#### (This one is related to the upcoming assignment.)\n",
    "\n",
    "Consider training models on the Argo profile to predict one of the depth, temperature and salinity from the other two (as a start). Do the usual data scaling, evaluation for robustness, cross-validation etc.\n",
    "\n",
    "An extra thing to do would be to evalute whether the predictions are physically plausible:\n",
    "\n",
    "* It is entirely possible the prediction leads to a density that is in fact gravitationally unstable, when we don't think this is likely the case\n",
    "* (Harder) The resulting density prediction leads to a contradicting the buoyancy frequency $N^2$ that is also present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb135db-3202-489c-adf3-279e93ef49a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746f05ec-2b9a-438c-947e-7b43258cec64",
   "metadata": {
    "id": "746f05ec-2b9a-438c-947e-7b43258cec64"
   },
   "source": [
    "## 7) Hyperparameter tuning and model selection\n",
    "\n",
    "#### (May help with all upcoming assignments.)\n",
    "\n",
    "Instead of doing things manually, have a look at [here](https://scikit-learn.org/stable/modules/grid_search.html#) to see how you might do hyperparameter tuning of the model. Within the same manual there are suggestions on how you might model selection also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef06af-5a86-4d5a-8730-7cb52dbbe1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fecccdf-df7d-4cd2-a993-0cdcfcd1eeb8",
   "metadata": {
    "id": "9fecccdf-df7d-4cd2-a993-0cdcfcd1eeb8"
   },
   "source": [
    "## 8) Spectral analysis\n",
    "\n",
    "If you have seen Fourier analysis before, consider doing dimension reduction / data compression via Fourier transform (e.g. `np.rfft` or similar); this is a fairly standard thing to do for acoustic data and signal processing for example (e.g. music identification software such as [Shazam](https://www.shazam.com/)), and maintains the feature orthogonality property.\n",
    "\n",
    "If you are feeling adventurous, you could try more general transforms (e.g. spherical harmonics, Bessel functions, wavelets).\n",
    "\n",
    "(There is then potentially something to be said about doing machine learning to predict things leveraging the data structure these spectral/wavelet spaces, which can be more stable and robust. See for example [this paper](https://www.nature.com/articles/s41467-021-21481-0) and maybe a video on YouTube by [Steve Brunton](https://www.youtube.com/watch?v=W8PybqAk6Ik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190927b-4e29-400c-87ac-f3e39dfd4fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b17452a-ac02-4fc9-ba94-6e2b5eaf3878",
   "metadata": {
    "id": "6b17452a-ac02-4fc9-ba94-6e2b5eaf3878"
   },
   "source": [
    "## 9) Time-series forecasting\n",
    "\n",
    "Consider taking something like the `elnino34_sst.data` and train a linear model to do forecasting: given previous now and maybe some previous time data (these are your $X$s), predict the next time (these are your $Y$s). These are basically [ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average)-like models but with no noise terms.\n",
    "\n",
    "How many previous times you put in is up to you, but note that if you use the whole time series your model will be complex and you have very few values to regress over. A shorter time series may allow you to do train/test split.\n",
    "\n",
    "If you need to, I suppose you could \"cheat\" and generate multiple similar time series by taking the `elnino34_sst.data` and add noise to it, and call that a new time series; this is a bit like ***bootstrapping*** I would imagine.\n",
    "\n",
    "(You could also do something a bit more controlled by generating your time-series with a model of your choice. A particularly simple one would be a predator-prey or [Lotka-Volterra model](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations); if you look into the OCES 3301 repository there should already be an implementation there. A harder one would be a [Lorenz system](https://en.wikipedia.org/wiki/Lorenz_system).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b253332-a595-4aeb-aac2-f89af224e6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
